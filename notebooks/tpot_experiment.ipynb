{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellenhoeven/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from tpot import TPOTClassifier, TPOTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and very quick preprocessing\n",
    "- Create target and features\n",
    "- Drop columns that are not needed\n",
    "- Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TrainingWiDS2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>hospital_admit_source</th>\n",
       "      <th>...</th>\n",
       "      <th>h1_pao2fio2ratio_max</th>\n",
       "      <th>h1_pao2fio2ratio_min</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>214826</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.732803</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>246060</td>\n",
       "      <td>81</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.421875</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>276985</td>\n",
       "      <td>118</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.952749</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>262220</td>\n",
       "      <td>118</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.635548</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>Operating Room</td>\n",
       "      <td>...</td>\n",
       "      <td>337.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>201746</td>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  encounter_id  hospital_id   age        bmi  elective_surgery  \\\n",
       "0           1        214826          118  68.0  22.732803                 0   \n",
       "1           2        246060           81  77.0  27.421875                 0   \n",
       "2           3        276985          118  25.0  31.952749                 0   \n",
       "3           4        262220          118  81.0  22.635548                 1   \n",
       "4           5        201746           33  19.0        NaN                 0   \n",
       "\n",
       "   ethnicity gender  height hospital_admit_source  ... h1_pao2fio2ratio_max  \\\n",
       "0  Caucasian      M   180.3                 Floor  ...                  NaN   \n",
       "1  Caucasian      F   160.0                 Floor  ...                 51.0   \n",
       "2  Caucasian      F   172.7  Emergency Department  ...                  NaN   \n",
       "3  Caucasian      F   165.1        Operating Room  ...                337.0   \n",
       "4  Caucasian      M   188.0                   NaN  ...                  NaN   \n",
       "\n",
       "   h1_pao2fio2ratio_min aids cirrhosis  hepatic_failure  immunosuppression  \\\n",
       "0                   NaN    0         0                0                  0   \n",
       "1                  51.0    0         0                0                  0   \n",
       "2                   NaN    0         0                0                  0   \n",
       "3                 337.0    0         0                0                  0   \n",
       "4                   NaN    0         0                0                  0   \n",
       "\n",
       "   leukemia  lymphoma  solid_tumor_with_metastasis  diabetes_mellitus  \n",
       "0         0         0                            0                  1  \n",
       "1         0         0                            0                  1  \n",
       "2         0         0                            0                  0  \n",
       "3         0         0                            0                  0  \n",
       "4         0         0                            0                  0  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['diabetes_mellitus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['diabetes_mellitus'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "X.drop(\"encounter_id\", axis = 1, inplace = True)\n",
    "X.drop(\"hospital_id\", axis = 1, inplace = True)\n",
    "X.drop(\"icu_id\", axis = 1, inplace = True)\n",
    "X.drop(\"icu_stay_type\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['elective_surgery',\n",
    "                   'ethnicity',\n",
    "                   'gender',\n",
    "                   'hospital_admit_source',\n",
    "                   'icu_admit_source',\n",
    "                   'icu_type',\n",
    "                   'readmission_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tmp = X.select_dtypes(exclude=['uint8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(),\n",
    "                                                    train_size=0.75, test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97617, 207)\n",
      "(32540, 207)\n",
      "(97617,)\n",
      "(32540,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start TPOT\n",
    "\n",
    "https://machinelearningmastery.com/tpot-for-automated-machine-learning-in-python/\n",
    "\n",
    "http://epistasislab.github.io/tpot/using/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a first simple pipeline to test if everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=2, \n",
    "                      population_size=2, \n",
    "                      verbosity=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/6 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -inf\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 self._pop, _ = eaMuPlusLambda(\n\u001b[0m\u001b[1;32m    731\u001b[0m                     \u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function, log_file)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mper_generation_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mper_generation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_check_periodic_pipeline\u001b[0;34m(self, gen)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \"\"\"\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiodic_checkpoint_folder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 raise RuntimeError('There was an error in the TPOT optimization '\n\u001b[0m\u001b[1;32m    839\u001b[0m                                    \u001b[0;34m'process. This could be because the data was '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-ae12113a2136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pipeline_optimizer.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    762\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;31m# Delete the temporary cache before exiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wids2021/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m                                                     error_score=\"raise\")\n\u001b[1;32m    837\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 raise RuntimeError('There was an error in the TPOT optimization '\n\u001b[0m\u001b[1;32m    839\u001b[0m                                    \u001b[0;34m'process. This could be because the data was '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                                    \u001b[0;34m'not formatted properly, or because data for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/"
     ]
    }
   ],
   "source": [
    "# pipeline_optimizer.fit(X_train, y_train)\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a more detailed pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "pipeline_optimizer = TPOTClassifier(generations=3, # 5, # default 100\n",
    "                      population_size=3, # 50,  # default 100\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      scoring='roc_auc',\n",
    "                      cv=cv,\n",
    "                      warm_start=True,\n",
    "                      periodic_checkpoint_folder='/tpot_checkpoints',\n",
    "                      early_stop=3)\n",
    "\n",
    "# perform search\n",
    "pipeline_optimizer.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_optimizer.score(X_test, y_test.values))\n",
    "\n",
    "# export the best model\n",
    "pipeline_optimizer.export('tpot_digits_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
